{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AryanRajSaxena/Leaf_disease/blob/main/Leaves_Identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN-S3ak7eKOa",
        "outputId": "3f9488d8-50c8-4cd9-cdd8-b4c9cb921316"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMXjk1Xdea7G",
        "outputId": "b2f23b70-51e5-4153-d530-f30571b22bc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-io\n",
            "  Downloading tensorflow_io-0.33.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (28.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.6/28.6 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-io-gcs-filesystem==0.33.0 (from tensorflow-io)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.33.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-io-gcs-filesystem, tensorflow-io\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.32.0\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.32.0:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.32.0\n",
            "Successfully installed tensorflow-io-0.33.0 tensorflow-io-gcs-filesystem-0.33.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaMHtRv7ebGI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Flatten\n",
        "from keras.applications.vgg16 import VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JW5_TS2Hak5m",
        "outputId": "54e84114-4d2f-4013-bd7a-c0c340b6a8ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "conv_base = VGG16(\n",
        "    weights='imagenet',\n",
        "    include_top = False,\n",
        "    input_shape=(224,224,3)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce2jWfiKa238",
        "outputId": "db32a498-9623-4923-a239-98f9cd3b778c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "conv_base.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qj0CN6tKa7jq"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(conv_base)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ma5O4WBqa-VC"
      },
      "outputs": [],
      "source": [
        "conv_base.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "mvFxcnh7Q6GO",
        "outputId": "2fb62f5b-ca74-4f2e-f510-87c8bdc36654"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b99ebc3063f0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m datagen = ImageDataGenerator(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mrotation_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Randomly rotate images by 20 degrees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mwidth_shift_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Randomly shift images horizontally by 20% of the total width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mheight_shift_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Randomly shift images vertically by 20% of the total height\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mshear_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Apply random shear transformations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
          ]
        }
      ],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,  # Randomly rotate images by 20 degrees\n",
        "    width_shift_range=0.2,  # Randomly shift images horizontally by 20% of the total width\n",
        "    height_shift_range=0.2,  # Randomly shift images vertically by 20% of the total height\n",
        "    shear_range=0.2,  # Apply random shear transformations\n",
        "    zoom_range=0.2,  # Randomly zoom in and out of images\n",
        "    horizontal_flip=True,  # Randomly flip images horizontally\n",
        "    fill_mode='nearest'  # Fill in any newly created pixels after rotation or shifting\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqx-6UWDebJT",
        "outputId": "e44529cc-f151-413d-96a7-fa7a5f301f51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 82 files belonging to 2 classes.\n",
            "Found 60 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory=\"/content/drive/MyDrive/Image/train\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    image_size=(224, 224)\n",
        ")\n",
        "\n",
        "validation_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory=\"/content/drive/MyDrive/Image/Val\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    image_size=(224, 224)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmyJ1MrwbZSx"
      },
      "outputs": [],
      "source": [
        "# Normalizing\n",
        "def process(image, label):\n",
        "    image = tf.cast(image / 255., tf.float32)\n",
        "    tfio.experimental.color.bgr_to_rgb(\n",
        "    image, name=None\n",
        "    )\n",
        "    return image, label\n",
        "\n",
        "\n",
        "train_ds = train_ds.map(process)\n",
        "validation_ds = validation_ds.map(process)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzGkRahbcB5T"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoPXSMV0cJIJ",
        "outputId": "5d3014f5-f0a4-41c7-a319-dd8fa6962179"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "3/3 [==============================] - 102s 22s/step - loss: 5.7157 - accuracy: 0.4756 - val_loss: 5.4320 - val_accuracy: 0.5167\n",
            "Epoch 2/35\n",
            "3/3 [==============================] - 18s 4s/step - loss: 4.5749 - accuracy: 0.6220 - val_loss: 6.0648 - val_accuracy: 0.5167\n",
            "Epoch 3/35\n",
            "3/3 [==============================] - 20s 5s/step - loss: 3.8506 - accuracy: 0.6220 - val_loss: 3.3331 - val_accuracy: 0.5167\n",
            "Epoch 4/35\n",
            "3/3 [==============================] - 18s 4s/step - loss: 1.6480 - accuracy: 0.6220 - val_loss: 0.6053 - val_accuracy: 0.6667\n",
            "Epoch 5/35\n",
            "3/3 [==============================] - 22s 5s/step - loss: 0.6101 - accuracy: 0.6220 - val_loss: 0.6900 - val_accuracy: 0.4833\n",
            "Epoch 6/35\n",
            "3/3 [==============================] - 21s 5s/step - loss: 0.6946 - accuracy: 0.3780 - val_loss: 0.6741 - val_accuracy: 0.6500\n",
            "Epoch 7/35\n",
            "3/3 [==============================] - 23s 5s/step - loss: 0.6517 - accuracy: 0.8171 - val_loss: 0.6709 - val_accuracy: 0.5167\n",
            "Epoch 8/35\n",
            "3/3 [==============================] - 20s 5s/step - loss: 0.6146 - accuracy: 0.6463 - val_loss: 0.6915 - val_accuracy: 0.5167\n",
            "Epoch 9/35\n",
            "3/3 [==============================] - 22s 5s/step - loss: 0.5992 - accuracy: 0.6220 - val_loss: 0.7231 - val_accuracy: 0.5167\n",
            "Epoch 10/35\n",
            "3/3 [==============================] - 22s 5s/step - loss: 0.5968 - accuracy: 0.6220 - val_loss: 0.7408 - val_accuracy: 0.5167\n",
            "Epoch 11/35\n",
            "3/3 [==============================] - 22s 5s/step - loss: 0.5830 - accuracy: 0.6341 - val_loss: 0.7181 - val_accuracy: 0.5167\n",
            "Epoch 12/35\n",
            "3/3 [==============================] - 18s 4s/step - loss: 0.5518 - accuracy: 0.6585 - val_loss: 0.6805 - val_accuracy: 0.5167\n",
            "Epoch 13/35\n",
            "3/3 [==============================] - 22s 5s/step - loss: 0.5138 - accuracy: 0.7317 - val_loss: 0.6157 - val_accuracy: 0.6333\n",
            "Epoch 14/35\n",
            "3/3 [==============================] - 23s 5s/step - loss: 0.4973 - accuracy: 0.8537 - val_loss: 0.5902 - val_accuracy: 0.6833\n",
            "Epoch 15/35\n",
            "3/3 [==============================] - 21s 5s/step - loss: 0.4789 - accuracy: 0.9024 - val_loss: 0.5884 - val_accuracy: 0.7000\n",
            "Epoch 16/35\n",
            "3/3 [==============================] - 22s 5s/step - loss: 0.4403 - accuracy: 0.9024 - val_loss: 0.6132 - val_accuracy: 0.6333\n",
            "Epoch 17/35\n",
            "3/3 [==============================] - 22s 5s/step - loss: 0.4121 - accuracy: 0.8537 - val_loss: 0.6614 - val_accuracy: 0.6167\n",
            "Epoch 18/35\n",
            "3/3 [==============================] - 20s 5s/step - loss: 0.3948 - accuracy: 0.8293 - val_loss: 0.6655 - val_accuracy: 0.6167\n",
            "Epoch 19/35\n",
            "3/3 [==============================] - 22s 5s/step - loss: 0.3660 - accuracy: 0.8537 - val_loss: 0.6203 - val_accuracy: 0.6500\n",
            "Epoch 20/35\n",
            "3/3 [==============================] - 21s 5s/step - loss: 0.3355 - accuracy: 0.8902 - val_loss: 0.5743 - val_accuracy: 0.7000\n",
            "Epoch 21/35\n",
            "3/3 [==============================] - 19s 5s/step - loss: 0.3162 - accuracy: 0.9146 - val_loss: 0.5647 - val_accuracy: 0.6833\n",
            "Epoch 22/35\n",
            "3/3 [==============================] - 22s 5s/step - loss: 0.2910 - accuracy: 0.9146 - val_loss: 0.6048 - val_accuracy: 0.6500\n",
            "Epoch 23/35\n",
            "3/3 [==============================] - 22s 5s/step - loss: 0.2671 - accuracy: 0.9024 - val_loss: 0.6419 - val_accuracy: 0.6500\n",
            "Epoch 24/35\n",
            "3/3 [==============================] - 22s 5s/step - loss: 0.2483 - accuracy: 0.9024 - val_loss: 0.6563 - val_accuracy: 0.6500\n",
            "Epoch 25/35\n",
            "3/3 [==============================] - 21s 5s/step - loss: 0.2287 - accuracy: 0.9146 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
            "Epoch 26/35\n",
            "3/3 [==============================] - 22s 5s/step - loss: 0.2081 - accuracy: 0.9634 - val_loss: 0.6046 - val_accuracy: 0.6667\n",
            "Epoch 27/35\n",
            "3/3 [==============================] - 31s 10s/step - loss: 0.1993 - accuracy: 0.9634 - val_loss: 0.6002 - val_accuracy: 0.6667\n",
            "Epoch 28/35\n",
            "3/3 [==============================] - 18s 5s/step - loss: 0.1830 - accuracy: 0.9634 - val_loss: 0.6556 - val_accuracy: 0.6667\n",
            "Epoch 29/35\n",
            "3/3 [==============================] - 22s 5s/step - loss: 0.1667 - accuracy: 0.9756 - val_loss: 0.7233 - val_accuracy: 0.6333\n",
            "Epoch 30/35\n",
            "3/3 [==============================] - 22s 5s/step - loss: 0.1567 - accuracy: 0.9634 - val_loss: 0.7400 - val_accuracy: 0.6333\n",
            "Epoch 31/35\n",
            "3/3 [==============================] - 21s 5s/step - loss: 0.1443 - accuracy: 0.9756 - val_loss: 0.6999 - val_accuracy: 0.6500\n",
            "Epoch 32/35\n",
            "3/3 [==============================] - 18s 4s/step - loss: 0.1318 - accuracy: 0.9878 - val_loss: 0.6828 - val_accuracy: 0.6667\n",
            "Epoch 33/35\n",
            "3/3 [==============================] - 21s 5s/step - loss: 0.1260 - accuracy: 0.9878 - val_loss: 0.6974 - val_accuracy: 0.6833\n",
            "Epoch 34/35\n",
            "3/3 [==============================] - 21s 5s/step - loss: 0.1175 - accuracy: 0.9878 - val_loss: 0.7210 - val_accuracy: 0.6833\n",
            "Epoch 35/35\n",
            "3/3 [==============================] - 21s 5s/step - loss: 0.1078 - accuracy: 1.0000 - val_loss: 0.7466 - val_accuracy: 0.6667\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_ds,epochs=35,validation_data=validation_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0iJUZXzgrjd"
      },
      "outputs": [],
      "source": [
        "test_img = r\"/content/Green.jpg\"\n",
        "image = cv2.imread(test_img)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tE-g_DU9mBDc"
      },
      "outputs": [],
      "source": [
        "image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Az82Xoo7mBFv"
      },
      "outputs": [],
      "source": [
        "image = cv2.resize(image,(256,256))\n",
        "test_input = image.reshape((256,256,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0JCxRPlmBIG"
      },
      "outputs": [],
      "source": [
        "test_input.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAlrvtNhmBLV"
      },
      "outputs": [],
      "source": [
        "result = model.predict(test_input)\n",
        "result"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWddSmulLymxTkK52BGRFT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}